{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e379f8e-0528-414d-a473-ce79b881c415",
   "metadata": {},
   "source": [
    "## PostgreSQL Query as PySpark Dataframe and PySpark Dataframe as PostgreSQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e026fc-0a48-4810-96db-e579b07444d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ec3a3c-fe51-4650-95cf-82e4afdcf72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.getenv(\"CONFIG_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f739652f-000d-49a1-a981-3426bdd20d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\danie\\\\.config\\\\config.ini'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83b5de-921e-4e6b-8106-a80394072592",
   "metadata": {},
   "source": [
    "Below is an example of what a config.ini file could contain:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e701e-4bdf-4a7c-846e-a7c94eb80d98",
   "metadata": {},
   "source": [
    "[postgresql]<br>\n",
    "jdbc_driver_path=.jdbc\\postgresql-42.7.5.jar<br>\n",
    "host=your_host<br>\n",
    "username=your_username<br>\n",
    "password=your_password<br>\n",
    "database=your_db_name<br>\n",
    "port=5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8669f9ff-a922-4c3a-b5e5-fb7b8d1eb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgresql_credentials(path: str):\n",
    "    config = configparser.ConfigParser()\n",
    "    \n",
    "    try:\n",
    "        config.read(path)\n",
    "    except ConfigFileNotFound:\n",
    "        print(\"config.ini file not found\")\n",
    "\n",
    "    return {\n",
    "        \"host\": config[\"postgresql\"][\"host\"],\n",
    "        \"port\": int(config[\"postgresql\"][\"port\"]),\n",
    "        \"database\": config[\"postgresql\"][\"database\"],\n",
    "        \"username\": config[\"postgresql\"][\"username\"],\n",
    "        \"password\": config[\"postgresql\"][\"password\"],\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"jdbc_driver_path\": Path.home() / config[\"postgresql\"][\"jdbc_driver_path\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10dcf2d-d26e-41a8-b551-7300dab82713",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = get_postgresql_credentials(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73587abb-e7b4-4b09-a264-d3e106fbd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.master(\"local[*]\")\n",
    "    .appName(\"Postgres\")\n",
    "    .config(\"spark.jars\", credentials[\"jdbc_driver_path\"])\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff618ce1-ebcf-42a3-a545-3a6bb21ea2e5",
   "metadata": {},
   "source": [
    "#### PostgreSQL Query as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c12223-c755-416c-93f4-107811b6cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT CURRENT_DATE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782858a7-67e1-459b-bd00-eb82e931cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF = (spark.read\n",
    "          .format(\"jdbc\")\n",
    "          .option(\"driver\", credentials[\"driver\"])\n",
    "          .option(\"url\", f'jdbc:postgresql://{credentials[\"host\"]}:{credentials[\"port\"]}/{credentials[\"database\"]}')\n",
    "          .option(\"user\", credentials[\"username\"])\n",
    "          .option(\"password\", credentials[\"password\"])\n",
    "          .option(\"query\", query)\n",
    "          .load()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dea0ff0-ee65-4b9a-b9f2-72ba331aeb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|current_date|\n",
      "+------------+\n",
      "|  2025-02-17|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f4c593-a7cb-4517-8822-634a1d15e05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('current_date', DateType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdbcDF.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2fa32-d7f0-4c76-89c5-70ac88da1b10",
   "metadata": {},
   "source": [
    "#### Dataframe as PostgreSQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f00288-aeba-4fec-84f3-703c6d1d400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(jdbcDF\n",
    "    .select(\"current_date\").write.format(\"jdbc\")\n",
    "    .option(\"url\", f'jdbc:postgresql://{credentials[\"host\"]}:{credentials[\"port\"]}/{credentials[\"database\"]}')\n",
    "    .option(\"driver\", credentials[\"driver\"])\n",
    "    .option(\"dbtable\", \"my_table\")\n",
    "    .option(\"user\", credentials[\"username\"])\n",
    "    .option(\"password\", credentials[\"password\"])\n",
    "    # https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameWriter.mode.html#pyspark.sql.DataFrameWriter.mode\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3e7733-ea34-4c02-97c8-518fab999b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c196350-e7e0-48e4-973d-a4a8184885e9",
   "metadata": {},
   "source": [
    "#### Using Context Manager (with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd769b5-dcb2-4b2e-a942-44d2a6533e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|current_date|\n",
      "+------------+\n",
      "|  2025-02-17|\n",
      "+------------+\n",
      "\n",
      "Completed saving dataframe as Postgres table\n"
     ]
    }
   ],
   "source": [
    "with (SparkSession.builder.master(\"local[*]\").appName(\"Postgres\").config(\"spark.jars\", credentials[\"jdbc_driver_path\"]).getOrCreate()) as spark:\n",
    "    query = \"SELECT CURRENT_DATE\"\n",
    "    jdbcDF = (\n",
    "        spark.read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"driver\", credentials[\"driver\"])\n",
    "        .option(\"url\", f'jdbc:postgresql://{credentials[\"host\"]}:{credentials[\"port\"]}/{credentials[\"database\"]}')\n",
    "        .option(\"user\", credentials[\"username\"])\n",
    "        .option(\"password\", credentials[\"password\"])\n",
    "        .option(\"query\", query)\n",
    "        .load()\n",
    "    )\n",
    "    jdbcDF.show()\n",
    "    \n",
    "    (jdbcDF\n",
    "        .select(\"current_date\").write.format(\"jdbc\")\n",
    "        .option(\"url\", f'jdbc:postgresql://{credentials[\"host\"]}:{credentials[\"port\"]}/{credentials[\"database\"]}')\n",
    "        .option(\"driver\", credentials[\"driver\"])\n",
    "        .option(\"dbtable\", \"my_table\")\n",
    "        .option(\"user\", credentials[\"username\"])\n",
    "        .option(\"password\", credentials[\"password\"])\n",
    "        # https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameWriter.mode.html#pyspark.sql.DataFrameWriter.mode\n",
    "        .mode(\"overwrite\")\n",
    "        .save()\n",
    "    )\n",
    "    print(\"Completed saving dataframe as Postgres table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.11 (pyspark_dev)",
   "language": "python",
   "name": "pyspark_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
