# Linux / Debian Installation Instructions

# Create a separate python environment with PySpark installed
# Spark SQL
pip install pyspark[sql]
# Install Pandas API on Spark and plotly
pip install pyspark[pandas_on_spark] plotly
# Optional if you want to create a separate jupyter kernel
pip install ipykernel
python -m ipykernel install --user --name your_env --display-name "Py3.9 (pyspark_dev)"

# Install Java 8, scala, and git
sudo apt install openjdk-8-jdk scala git

# Install source for Spark 3.2.0
wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz

# Extract Spark to /opt/spark
sudo mkdir /opt/spark
sudo tar -xf spark*.tgz -C /opt/spark --strip-component 1

# Change permission to /opt/spark so that Spark can write inside it
sudo chmod -R 777 /opt/spark

# Edit .profile or .bashrc to add environment variables: SPARK_HOME
export SPARK_HOME=/opt/spark

# Add spark/bin and spark/sbin to the PATH environment variable
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

# Then create PYSPARK_PYTHON environment variable that points to your system Python interpreter
export PYSPARK_PYTHON=/usr/bin/python3

# Refresh .profile or .bashrc
source ~/.profile


# For Windows 10
Install Java 8 from old Sun Microsystem's site, not Oracle:  https://www.java.com/download/ie_manual.jsp

# Create separate Python virtual environment comtaining PySpark, Pandas API on Spark, and Plotly
pip install pyspark[sql]
pip install pyspark[pandas_on_spark] plotly
# Optional if you want to create a separate jupyter kernel
pip install ipykernel
python -m ipykernel install --user --name your_env --display-name "Py3.9 (pyspark_dev)"

# Set SPARK_HOME and PYSPARK_PYTHON environment variables
# Why point SPARK_HOME to site-packages/pyspark?  https://stackoverflow.com/questions/46286436/running-pyspark-after-pip-install-pyspark/49587560
set SPARK_HOME=<path_to_site_packages/pyspark_folder>
set PYSPARK_PYTHON=<path_to_python.exe>

# Trick Spark into thinking that you have Hadoop installed
Download winutils.exe from https://github.com/cdarlint/winutils, save locally to "hadoop/bin" folder and then
set HADOOP_HOME=[path_to_hadoop_folder]

# Update PATH to include hadoop/bin folder
set PATH=%PATH%;%HADOOP_HOME%\bin
